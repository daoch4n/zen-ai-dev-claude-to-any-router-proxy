# OpenRouter Anthropic Server Configuration Example
# Copy this file to .env and update with your values

# ==================== REQUIRED CONFIGURATION ====================

# Unified Proxy Backend Configuration
# Controls which backend to route /v1/messages requests to
# Options: OPENROUTER, AZURE_DATABRICKS, LITELLM_OPENROUTER, LITELLM_MESSAGES
# - OPENROUTER: Routes directly to OpenRouter (recommended for performance)
# - AZURE_DATABRICKS: Routes directly to Azure Databricks Claude endpoints
# - LITELLM_OPENROUTER: Routes through LiteLLM to OpenRouter (for advanced features)
# - LITELLM_MESSAGES: Routes to LiteLLM's native /v1/messages endpoint (no format conversion)
PROXY_BACKEND=LITELLM_MESSAGES

# OpenRouter API Configuration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-api-key-here

# Server Configuration
HOST=0.0.0.0
PORT=4000
ENVIRONMENT=production
LOG_LEVEL=INFO
DEBUG=false
DEBUG_LOGS_DIR=logs/debug

# Model Configuration
# Model names for OpenRouter integration (used when PROXY_BACKEND=OPENROUTER or LITELLM_OPENROUTER)
ANTHROPIC_MODEL=anthropic/claude-sonnet-4
ANTHROPIC_SMALL_FAST_MODEL=anthropic/claude-3.7-sonnet

# Request Configuration
MAX_TOKENS_LIMIT=8192
REQUEST_TIMEOUT=300
MAX_CONCURRENT_REQUESTS=10

# Performance Configuration
ENABLE_CACHING=true
CACHE_TTL=3600

# Instructor Configuration
INSTRUCTOR_ENABLED=true
INSTRUCTOR_TEMPERATURE=0.1
INSTRUCTOR_MAX_RETRIES=3

# ==================== BACKEND-SPECIFIC CONFIGURATION ====================

# ------------------ AZURE_DATABRICKS Backend ------------------
# Required when PROXY_BACKEND=AZURE_DATABRICKS
# Your workspace instance name (without .azuredatabricks.net)
# DATABRICKS_HOST=adb-1234567890123456.7
# DATABRICKS_TOKEN=dapi1234567890abcdef
# DATABRICKS_TIMEOUT=30.0
# DATABRICKS_MAX_RETRIES=3

# Optional endpoint names (defaults shown)
# DATABRICKS_CLAUDE_SONNET_4_ENDPOINT=databricks-claude-sonnet-4
# DATABRICKS_CLAUDE_3_7_SONNET_ENDPOINT=databricks-claude-3-7-sonnet

# ------------------ LITELLM_OPENROUTER Backend ------------------
# Required when PROXY_BACKEND=LITELLM_OPENROUTER
# Master key is a security key YOU create to protect your LiteLLM proxy
# You can use any secure string - this is NOT from an external service
# LITELLM_MASTER_KEY=sk-1234567890abcdef
# LITELLM_API_BASE=http://localhost:4001
# LITELLM_LOG_LEVEL=INFO
# LITELLM_TIMEOUT=120
# LITELLM_NUM_RETRIES=3

# ------------------ LITELLM_MESSAGES Backend (NEW) ------------------
# Required when PROXY_BACKEND=LITELLM_MESSAGES
# Uses LiteLLM's native /v1/messages endpoint (no format conversion!)
# LITELLM_BASE_URL=http://localhost:4001
# LITELLM_LOG_LEVEL=INFO

# ==================== OPTIONAL CONFIGURATION ====================

# Unified Logging Configuration
USE_UNIFIED_LOGGING=true
JSON_LOGS=false
UNIFIED_LOGS_DIR=logs
UNIFIED_LOG_FILE_ROTATION=daily
UNIFIED_LOG_RETENTION_DAYS=30

# Cache Configuration (for LiteLLM backends)
CACHE_TYPE=local
# For Redis cache:
# CACHE_TYPE=redis
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=your-redis-password
# REDIS_URL=redis://localhost:6379

# Budget and Cost Management (for LiteLLM backends)
BUDGET_TRACKING_ENABLED=false
# MAX_BUDGET_USD=100.0
# BUDGET_DURATION=monthly
COST_TRACKING_ENABLED=true

# Health Monitoring
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=60
MODEL_HEALTH_CHECKS=true

# Audit and Logging
AUDIT_LOGGING_ENABLED=false
REQUEST_LOGGING_ENABLED=true
RESPONSE_LOGGING_ENABLED=false

# Performance and Scaling
CONNECTION_POOL_SIZE=100
MAX_CONCURRENT_LITELLM_REQUESTS=50

# Tool Execution Configuration
TOOL_EXECUTION_ENABLED=true
TOOL_EXECUTION_TIMEOUT=30
# Set to your project workspace directory
TOOL_WORKING_DIRECTORY=./
TOOL_MAX_FILE_SIZE=10485760
TOOL_DEBUG_ENABLED=false
TOOL_MAX_CONCURRENT_TOOLS=5

# Tool Security
TOOL_SECURITY_STRICT_MODE=true
TOOL_SECURITY_ALLOW_ABSOLUTE_PATHS=false
TOOL_SECURITY_MAX_PATH_DEPTH=10

# Tool Rate Limiting
TOOL_RATE_LIMIT_WINDOW=60
TOOL_RATE_LIMIT_MAX_REQUESTS=100

# Proxy Configuration (Optional)
# Uncomment and configure if you need to use a proxy server
# HTTP_PROXY=http://your-proxy-server:port
# HTTPS_PROXY=http://your-proxy-server:port
# NO_PROXY=localhost,127.0.0.1,::1

# ==================== INSTRUCTIONS ====================
# 1. Copy this file to .env: cp env.example .env
# 2. Replace the placeholder values with your actual API key and desired settings
# 3. Choose your preferred backend by setting PROXY_BACKEND:
#    - OPENROUTER: Direct OpenRouter integration (fastest, recommended)
#    - AZURE_DATABRICKS: Azure Databricks Claude endpoints (requires Databricks setup)
#    - LITELLM_OPENROUTER: LiteLLM-mediated OpenRouter (for advanced features)
#    - LITELLM_MESSAGES: LiteLLM native Anthropic format (no conversion needed)
# 4. Configure backend-specific settings as needed
# 5. Configure proxy settings if needed (uncomment and set values)
# 6. Never commit the .env file to version control

# ==================== EXAMPLE CONFIGURATIONS ====================

# Example 1: Production with OPENROUTER (Recommended)
# PROXY_BACKEND=OPENROUTER
# ENVIRONMENT=production
# LOG_LEVEL=WARNING
# DEBUG=false
# JSON_LOGS=true

# Example 2: Development with LITELLM_MESSAGES (Native Anthropic format)
# PROXY_BACKEND=LITELLM_MESSAGES
# LITELLM_BASE_URL=http://localhost:4001
# ENVIRONMENT=development
# LOG_LEVEL=DEBUG
# DEBUG=true

# Example 3: Azure Databricks Integration
# PROXY_BACKEND=AZURE_DATABRICKS
# DATABRICKS_HOST=your-workspace-instance
# DATABRICKS_TOKEN=your-token
# ENVIRONMENT=production

# Example 4: LiteLLM with Advanced Features
# PROXY_BACKEND=LITELLM_OPENROUTER
# LITELLM_MASTER_KEY=your-secure-key
# CACHE_TYPE=redis
# REDIS_URL=redis://localhost:6379
# BUDGET_TRACKING_ENABLED=true
# MAX_BUDGET_USD=1000.0 