# BetaMessage
## Properties

| Name | Type | Description | Notes |
|------------ | ------------- | ------------- | -------------|
| **id** | **String** | Unique object identifier.  The format and length of IDs may change over time. | [default to null] |
| **type** | **String** | Object type.  For Messages, this is always &#x60;\&quot;message\&quot;&#x60;. | [default to message] |
| **role** | **String** | Conversational role of the generated message.  This will always be &#x60;\&quot;assistant\&quot;&#x60;. | [default to assistant] |
| **content** | [**List**](BetaContentBlock.md) | Content generated by the model.  This is an array of content blocks, each of which has a &#x60;type&#x60; that determines its shape.  Example:  &#x60;&#x60;&#x60;json [{\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;Hi, I&#39;m Claude.\&quot;}] &#x60;&#x60;&#x60;  If the request input &#x60;messages&#x60; ended with an &#x60;assistant&#x60; turn, then the response &#x60;content&#x60; will continue directly from that last turn. You can use this to constrain the model&#39;s output.  For example, if the input &#x60;messages&#x60; were: &#x60;&#x60;&#x60;json [   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;What&#39;s the Greek name for Sun? (A) Sol (B) Helios (C) Sun\&quot;},   {\&quot;role\&quot;: \&quot;assistant\&quot;, \&quot;content\&quot;: \&quot;The best answer is (\&quot;} ] &#x60;&#x60;&#x60;  Then the response &#x60;content&#x60; might be:  &#x60;&#x60;&#x60;json [{\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;B)\&quot;}] &#x60;&#x60;&#x60; | [default to null] |
| **model** | [**Model**](Model.md) |  | [default to null] |
| **stop\_reason** | **String** |  | [default to null] |
| **stop\_sequence** | **String** |  | [default to null] |
| **usage** | [**BetaUsage**](BetaUsage.md) | Billing and rate-limit usage.  Anthropic&#39;s API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.  Under the hood, the API transforms requests into a format suitable for the model. The model&#39;s output then goes through a parsing stage before becoming an API response. As a result, the token counts in &#x60;usage&#x60; will not match one-to-one with the exact visible content of an API request or response.  For example, &#x60;output_tokens&#x60; will be non-zero, even for an empty string response from Claude. | [default to null] |

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)

